{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxJucrKj7mHJ"
   },
   "source": [
    "# Lab 2.1 - Weather Data Around Winona\n",
    "\n",
    "In this lab, we will download and combine a decades worth of weather data from the NOAA, focusing on weather stations within 500 miles of Winona.\n",
    "\n",
    "Here is the outline of the basic process.\n",
    "\n",
    "1. Install and investigate useful packages.\n",
    "2. Find all weather stations in proximity to Winona.\n",
    "3. Use a single station to prototype our tools.\n",
    "4. Automate the process of downloading and uncompressing data from all stations of interest.\n",
    "5. Output the results to a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeicFuT-8Vnx"
   },
   "source": [
    "## Problem 1 - Install and investigate useful tools.\n",
    "\n",
    "First, you should install and investigate the following tools.\n",
    "\n",
    "1. **`wget`** is a tool for programmically downloading data files from the web on the command line.  There is a Python wrapper to this tool that you can install with `pip` as shown below.\n",
    "2. **`geopy`** is a package that, among other things, implements a function for computing distances between two lat-long pairs. Again, install this package with `pip` as shown below.\n",
    "3. **`gzip`** is part of the standard Python library and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c8pRv9PyCvPy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\mp5667di\\appdata\\local\\anaconda3\\envs\\polars\\lib\\site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uPWEksjS9REC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in c:\\users\\mp5667di\\appdata\\local\\anaconda3\\envs\\polars\\lib\\site-packages (2.4.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\mp5667di\\appdata\\local\\anaconda3\\envs\\polars\\lib\\site-packages (from geopy) (2.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import geopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQXgqoPb9e53"
   },
   "source": [
    "#### Task 1.1 - Investigate using `wget` to download a file.\n",
    "\n",
    "Read the help/documentation on `wget` to figure out how to download the following data file [Some random data file from STAT 210] into the `./data` sub-folder.\n",
    "\n",
    "[https://github.com/yardsale8/STAT_210/raw/refs/heads/main/data/sars1.csv](https://github.com/yardsale8/STAT_210/raw/refs/heads/main/data/sars1.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module wget:\n",
      "\n",
      "NAME\n",
      "    wget - Download utility as an easy way to get file from the net\n",
      "\n",
      "DESCRIPTION\n",
      "      python -m wget <URL>\n",
      "      python wget.py <URL>\n",
      "\n",
      "    Downloads: http://pypi.python.org/pypi/wget/\n",
      "    Development: http://bitbucket.org/techtonik/python-wget/\n",
      "\n",
      "    wget.py is not option compatible with Unix wget utility,\n",
      "    to make command line interface intuitive for new people.\n",
      "\n",
      "    Public domain by anatoly techtonik <techtonik@gmail.com>\n",
      "    Also available under the terms of MIT license\n",
      "    Copyright (c) 2010-2015 anatoly techtonik\n",
      "\n",
      "FUNCTIONS\n",
      "    bar_adaptive(current, total, width=80)\n",
      "        Return progress bar string for given values in one of three\n",
      "        styles depending on available width:\n",
      "\n",
      "            [..  ] downloaded / total\n",
      "            downloaded / total\n",
      "            [.. ]\n",
      "\n",
      "        if total value is unknown or <= 0, show bytes counter using two\n",
      "        adaptive styles:\n",
      "\n",
      "            %s / unknown\n",
      "            %s\n",
      "\n",
      "        if there is not enough space on the screen, do not display anything\n",
      "\n",
      " used toreturned string doesn't include control characters like \n",
      "        place cursor at the beginning of the line to erase previous content.\n",
      "\n",
      "        this function leaves one free character at the end of string to\n",
      "        avoid automatic linefeed on Windows.\n",
      "\n",
      "    bar_thermometer(current, total, width=80)\n",
      "        Return thermometer style progress bar string. `total` argument\n",
      "        can not be zero. The minimum size of bar returned is 3. Example:\n",
      "\n",
      "            [..........            ]\n",
      "\n",
      " and spaces) are not included.ymbols (\n",
      "        See `bar_adaptive` for more information.\n",
      "\n",
      "    callback_progress(blocks, block_size, total_size, bar_function)\n",
      "        callback function for urlretrieve that is called when connection is\n",
      "        created and when once for each block\n",
      "\n",
      "        draws adaptive progress bar in terminal/console\n",
      "\n",
      "        use sys.stdout.write() instead of \"print,\", because it allows one more\n",
      "        symbol at the line end without linefeed on Windows\n",
      "\n",
      "        :param blocks: number of blocks transferred so far\n",
      "        :param block_size: in bytes\n",
      "        :param total_size: in bytes, can be -1 if server doesn't return it\n",
      "        :param bar_function: another callback function to visualize progress\n",
      "\n",
      "    detect_filename(url=None, out=None, headers=None, default='download.wget')\n",
      "        Return filename for saving file. If no filename is detected from output\n",
      "        argument, url or headers, return default (download.wget)\n",
      "\n",
      "    download(url, out=None, bar=<function bar_adaptive at 0x0000024357558180>)\n",
      "        High level function, which downloads URL into tmp file in current\n",
      "        directory and then renames it to filename autodetected from either URL\n",
      "        or HTTP headers.\n",
      "\n",
      "        :param bar: function to track download progress (visualize etc.)\n",
      "        :param out: output filename or directory\n",
      "        :return:    filename where URL is downloaded to\n",
      "\n",
      "    filename_fix_existing(filename)\n",
      "        Expands name portion of filename with numeric ' (x)' suffix to\n",
      "        return filename that doesn't exist already.\n",
      "\n",
      "    filename_from_headers(headers)\n",
      "        Detect filename from Content-Disposition headers if present.\n",
      "        http://greenbytes.de/tech/tc2231/\n",
      "\n",
      "        :param: headers as dict, list or string\n",
      "        :return: filename from content-disposition header or None\n",
      "\n",
      "    filename_from_url(url)\n",
      "        :return: detected filename as unicode or None\n",
      "\n",
      "    get_console_width()\n",
      "        Return width of available window area. Autodetection works for\n",
      "        Windows and POSIX platforms. Returns 80 for others\n",
      "\n",
      "        Code from http://bitbucket.org/techtonik/python-pager\n",
      "\n",
      "    to_unicode(filename)\n",
      "        :return: filename decoded from utf-8 to unicode\n",
      "\n",
      "    win32_unicode_console()\n",
      "        # enable unicode output to windows console\n",
      "        # https://stackoverflow.com/questions/878972/windows-cmd-encoding-change-causes-python-crash\n",
      "\n",
      "    win32_utf8_argv()\n",
      "        Uses shell32.GetCommandLineArgvW to get sys.argv as a list of Unicode\n",
      "        strings.\n",
      "\n",
      "        Versions 2.x of Python don't support Unicode in sys.argv on\n",
      "        Windows, with the underlying Windows API instead replacing multi-byte\n",
      "        characters with '?'.\n",
      "\n",
      "DATA\n",
      "    PY3K = True\n",
      "    usage = 'usage: wget.py [options] URL\\n\\noptions:\\n  -o --ou...ut file...\n",
      "\n",
      "VERSION\n",
      "    3.2\n",
      "\n",
      "FILE\n",
      "    c:\\users\\mp5667di\\appdata\\local\\anaconda3\\envs\\polars\\lib\\site-packages\\wget.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(wget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "D92NkCq_995Z"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 182D-87E4\n",
      "\n",
      " Directory of C:\\Users\\mp5667di\\OneDrive - Minnesota State\\Desktop\\Spring_2025\\DSCI_330\\lab_2.1_Weather_data_around_Winona\n",
      "\n",
      "01/28/2025  09:24 AM    <DIR>          .\n",
      "01/28/2025  08:11 AM    <DIR>          ..\n",
      "01/28/2025  08:18 AM                66 .gitattributes\n",
      "01/28/2025  08:23 AM    <DIR>          .ipynb_checkpoints\n",
      "01/28/2025  09:16 AM    <DIR>          data\n",
      "01/28/2025  09:24 AM            44,107 lab2_1_weather_data_around_winona.ipynb\n",
      "01/28/2025  08:18 AM                39 README.md\n",
      "               3 File(s)         44,212 bytes\n",
      "               4 Dir(s)  50,560,499,712 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: ./data/sars1 (1).csv\n"
     ]
    }
   ],
   "source": [
    "url = \"https://github.com/yardsale8/STAT_210/raw/refs/heads/main/data/sars1.csv\"\n",
    "output_path = \"./data/sars1.csv\"  # My file path\n",
    "\n",
    "filename = wget.download(url, out=output_path)\n",
    "\n",
    "print(f\"File downloaded to: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTW9hZXX-Ceq"
   },
   "source": [
    "#### Task 1.2 - Investigate using `geopy.distance.distance` to compute a distance in miles.\n",
    "\n",
    "1. Import the `distance` function from the `geopy.distance` submodule.\n",
    "2. Use Wikipedia to find the lat-long coordinates of Winona and Rochester MN.\n",
    "3. Use `distance` to compute the distance between Winona and Rochester.\n",
    "4. Use some other source (e.g., Google Maps) to check the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "m-XZZQ2v-i4t"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winona: 44.050556, -91.668333\n",
    "# Rochester: 44.023333, -92.461389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.54418575388878\n"
     ]
    }
   ],
   "source": [
    "winona = (44.050556, -91.668333)\n",
    "rochester = (44.023333, -92.461389)\n",
    "\n",
    "print(distance.distance(winona, rochester).miles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHdoE7ZFBXlU"
   },
   "source": [
    "#### Task 1.3 - Investigate `gzip`\n",
    "\n",
    "The yearly NOAA data is compressed as `.gz` files, which need to be uncompressed using `gzip`.  Explore the `gzip` module by\n",
    "\n",
    "1. Exploring the documentation/help for the `gzip` module,\n",
    "2. Using `wget` to download the following link into the `./data` folder, and\n",
    "3. Using `gzip` to uncompress this file.\n",
    "4. Inspect the data in your list, which should be of type `byte`.  Use a comprehension with the expression `l.decode('utf-8')` to convert this to a list of strings.\n",
    "5. Write the uncompressed lines to an output file using `with open(path, 'w') as out` and the `writelines` method of `out`.  \n",
    "\n",
    "**Link.** [https://www.ncei.noaa.gov/pub/data/ghcn/daily/by_year/1750.csv.gz](https://www.ncei.noaa.gov/pub/data/ghcn/daily/by_year/1750.csv.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "88NVuihyCBBO"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This command is not supported by the help utility.  Try \"(gzip) /?\".\n"
     ]
    }
   ],
   "source": [
    "!help(gzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded to: ./data/1750.csv (1).gz\n"
     ]
    }
   ],
   "source": [
    "# Download the file into the ./data folder\n",
    "url = \"https://www.ncei.noaa.gov/pub/data/ghcn/daily/by_year/1750.csv.gz\"\n",
    "output_path = \"./data/1750.csv.gz\"  # My file path\n",
    "\n",
    "filename = wget.download(url, out=output_path)\n",
    "\n",
    "print(f\"File downloaded to: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncompressed file saved as: ./data/1750_uncompressed.csv\n"
     ]
    }
   ],
   "source": [
    "# Define input and output file paths\n",
    "file_to_uncompress = './data/1750.csv.gz'\n",
    "output_file = './data/1750_uncompressed.csv'\n",
    "\n",
    "# Step 1: Read the compressed file as bytes\n",
    "with open(file_to_uncompress, 'rb') as f:\n",
    "    compressed_data = f.read()  # Read the entire file in binary mode\n",
    "\n",
    "# Step 2: Decompress the data\n",
    "decompressed_data = gzip.decompress(compressed_data)  # Returns bytes\n",
    "\n",
    "# Step 3: Convert bytes to string and split into lines\n",
    "string_lines = decompressed_data.decode('utf-8').splitlines(keepends=True)\n",
    "\n",
    "# Step 4: Write the uncompressed lines to an output file\n",
    "with open(output_file, 'w') as out:\n",
    "    out.writelines(string_lines)\n",
    "\n",
    "print(f\"Uncompressed file saved as: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vt1MlIz9DWpm"
   },
   "source": [
    "## Problem 2 - Find all stations within 500 miles of Winona, MN.\n",
    "\n",
    "The file linked below contains information about all stations tracked by NOAA.  \n",
    "\n",
    "*Main folder:* https://www.ncei.noaa.gov/pub/data/ghcn/daily/\n",
    "\n",
    "*Station txt file:* https://www.ncei.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt\n",
    "\n",
    "*Note.* While it would be easier to use the CSV version of the station file, you should use the TXT version here (for practice).\n",
    "\n",
    "**Your tasks** Our goal is to get a list of stations that are within 500 miles of Winona.  Do this by\n",
    "\n",
    "1. Using `wget` to download the stations information into the `./data` folder.\n",
    "2. Use `with` to read the lines of this file.\n",
    "3. At this point, the lines are strings in a fixed-width format separated by whitespace.  Use a list comprehension with the string split method to split the raw lines (strings) into a list of entries.\n",
    "4. There are three entries of interest, the station ID and the lat-long coordinates of the station.  Inspect the file to determine the index for these three entries.\n",
    "5. We want to transform the lines (currently a list of strings) into a record, which is a `dict` with good names for the entries as keys and the values representing the data in an appropriate type (string for station ID, `float` for the lat-long).  Use a comprehension to create a list of records as described.\n",
    "6. Use another comprehension to apply a filter to the stations, keeping only those within 500 miles of Winona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F0J443KoFTrs"
   },
   "outputs": [],
   "source": [
    "# Your code here (add cells as needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7_9ve26IduT"
   },
   "source": [
    "#### Problem 3 - Prototype downloading and uncompressing a station file.\n",
    "\n",
    "Before we download and uncompress all the stations of interest, let's practice on one station file.\n",
    "\n",
    "\n",
    "1. Copy the url for some station and store is as a variable named `url`.\n",
    "2. Write `lambda` functions that extract each of the following from the station `url`: compressed file name, compressed file path (e.g., `./data/...`), and uncompressed file path (e.g., `./data/...`).\n",
    "3. Write a `lambda` function that extracts\n",
    "4. Use `wget` to download this stations data.\n",
    "5. Use `gzip` to uncompress the data.\n",
    "6. Write the data to out output file.\n",
    "\n",
    "Your code should have the following shape:\n",
    "\n",
    "```{Python}\n",
    "wget.download(...)\n",
    "with gzip.open(...) as f:\n",
    "    with open(..., 'w') as out:\n",
    "        f.readlines()\n",
    "        out.writelines(f)\n",
    "```\n",
    "\n",
    "You should be using your helper functions to, in part, fill in the `...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04YS60A1JciS"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzgFqv5VF38i"
   },
   "source": [
    "## Problem 4 - Build the station URLs and download the files.\n",
    "\n",
    "**Tasks.** Now you need to build urls for all stations of interest by\n",
    "\n",
    "1. Use a comprehension to extract the stations of interest into a list.\n",
    "2. Investigating the structure of the files stored in the `by_station` folder (see main folder link above).\n",
    "3. Use a comprehension and an `f` string to build a list of URLS for all stations of interest.\n",
    "4. Use `wget` to download the data for the stations of interest into the data folder.\n",
    "5. Use `gzip` to uncompress the files.\n",
    "6. Convert the `bytes` to `str` of format `utf-8`.\n",
    "7. Use the append mode `\"a\"` of `open` with `writelines` to append the data in each file to your output file.\n",
    "\n",
    "While we usually avoid using a `for` loop, we make an exception for code for lengthy IO.  To accomplish steps 4 & 5, use a `for` loop with the following shape.\n",
    "\n",
    "```{Python}\n",
    "for url in station_urls:\n",
    "    wget.download(...)\n",
    "    with gzip.open(...) as f:\n",
    "        with open(..., 'a') as out:\n",
    "            f.readlines()\n",
    "            ... # Convert lines to strings here\n",
    "            out.writelines(f)\n",
    "    print(f\"Downloaded and extracted the data for {url}\")\n",
    "```\n",
    "\n",
    "Note that the code inside the loop should resemble the code from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOUt7rCBIZ6f"
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "tnGWOC1xF9kT",
    "outputId": "9b060cfe-aa8e-4930-880c-b720a36fc911"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://my_fake_website.cool/A123456789'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_station = \"A123456789\"\n",
    "make_fake_url = lambda s: f\"https://my_fake_website.cool/{s}\"\n",
    "\n",
    "make_fake_url(fake_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RPvTJEJGYtc",
    "outputId": "da643b74-66a9-4b29-8cce-a679a2d9fa5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://my_fake_website.cool/A0',\n",
       " 'https://my_fake_website.cool/A1',\n",
       " 'https://my_fake_website.cool/A2',\n",
       " 'https://my_fake_website.cool/A3',\n",
       " 'https://my_fake_website.cool/A4',\n",
       " 'https://my_fake_website.cool/A5',\n",
       " 'https://my_fake_website.cool/A6',\n",
       " 'https://my_fake_website.cool/A7',\n",
       " 'https://my_fake_website.cool/A8',\n",
       " 'https://my_fake_website.cool/A9']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_fake_stations =[f'A{i}' for i in range(10)]\n",
    "\n",
    "(my_fake_urls := [make_fake_url(s) for s in my_fake_stations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVG4xpnvMvRK"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
